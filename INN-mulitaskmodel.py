# -*- coding: utf-8 -*-
"""mobilenet-unet (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KpMPsT0-dTTHgnLbivP7beWE5DSxiYyP
"""

!pip install git+https://github.com/lucasb-eyer/pydensecrf.git

from IPython.display import clear_output

!pip install -q tensorflow==2.4.1

clear_output()

import os
import numpy as np
import pandas as pd
from glob import glob
import random

import cv2
import matplotlib.pyplot as plt

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.data import Dataset
from tensorflow.keras import layers
from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2

import pydensecrf.densecrf as dcrf
# Setting seeds for reproducibility.
SEED = 42
tf.random.set_seed(SEED)
np.random.seed(SEED)
random.seed(SEED)

gpus = tf.config.list_physical_devices(device_type='GPU')
tf.config.set_visible_devices(gpus, device_type='GPU')

IMAGE_DIR = '/kaggle/input/fire-data/Images/Images'
MASK_DIR = '/kaggle/input/fire-data/Masks/Masks'
BATCH_SIZE=4
EPOCHS=10
LR = 1e-4
HEIGHT = 512
WIDTH = 512

sample_mask = cv2.imread('/kaggle/input/fire-data/Masks/Masks/image_0.png',cv2.IMREAD_GRAYSCALE)
num_classes = np.max(sample_mask) + 1
height = sample_mask.shape[0]
width = sample_mask.shape[1]
print('the number of total classes: ', num_classes)
print('sample image height {}, width {}'.format(height, width))

image_paths = glob(os.path.join(IMAGE_DIR, '*.jpg'))
image_paths.sort()
mask_paths = glob(os.path.join(MASK_DIR, '*.png'))
mask_paths.sort()
print('total number of images: ', len(image_paths))

data = pd.DataFrame(np.array([image_paths, mask_paths]).T, columns=['image','mask'])
print(data.iloc[0,0])
print(data.iloc[0,1])

from sklearn.model_selection import train_test_split

train_x, test_x, train_y, test_y = train_test_split(image_paths, mask_paths, test_size=0.1, random_state=19)
print('total number of images in training set: ', len(train_x))
print('total number of images in testing set: ', len(test_x))

def read_image(image_path, mask_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [HEIGHT, WIDTH])
    image = image / 255.0

    mask = tf.io.read_file(mask_path)
    mask = tf.image.decode_png(mask, channels=1)
    mask = tf.image.resize(mask, [HEIGHT, WIDTH])
    mask = tf.cast(tf.squeeze(mask), dtype=tf.int32)
    mask = tf.one_hot(mask, num_classes, dtype=tf.int32)
    return image, mask

def augment_image_batch1(image, mask):
    new_seed = np.random.randint(100)
    print(image.shape)
    print(mask.shape)
    image = tf.image.resize(image, [int(1.2 * HEIGHT), int(1.2 * WIDTH)])
    mask = tf.image.resize(mask, [int(1.2 * HEIGHT), int(1.2 * WIDTH)])
    image = tf.image.random_crop(image, (HEIGHT, WIDTH, 3), seed=new_seed)
    mask = tf.image.random_crop(mask, (HEIGHT, WIDTH, num_classes), seed=new_seed)
    image = tf.image.random_flip_left_right(image, seed=new_seed)
    mask = tf.image.random_flip_left_right(mask, seed=new_seed)
    mask = tf.cast(mask, dtype=tf.int32)
    return image,mask

def augment_image_batch2(image, mask):
    new_seed = np.random.randint(100)
    image = tf.image.resize(image, [int(1.2 * HEIGHT), int(1.2 * WIDTH)])
    mask = tf.image.resize(mask, [int(1.2 * HEIGHT), int(1.2 * WIDTH)])
    image = tf.image.random_crop(image, (HEIGHT, WIDTH, 3), seed=new_seed)
    mask = tf.image.random_crop(mask, (HEIGHT, WIDTH, num_classes), seed=new_seed)
    image = tf.image.random_flip_up_down(image, seed=new_seed)
    mask = tf.image.random_flip_up_down(mask, seed=new_seed)
    mask = tf.cast(mask, dtype=tf.int32)
    return image,mask

train_ds = Dataset.from_tensor_slices((train_x, train_y))
train_ds = train_ds.map(read_image)
train_ds1 = train_ds.map(augment_image_batch1)
train_ds2 = train_ds.map(augment_image_batch2)
train_ds = train_ds.concatenate(train_ds1.concatenate(train_ds2))
train_ds = train_ds.batch(BATCH_SIZE)
train_ds = train_ds.shuffle(True)
train_ds = train_ds.prefetch(tf.data.AUTOTUNE)

test_ds = Dataset.from_tensor_slices((test_x, test_y))
test_ds = test_ds.map(read_image)
test_ds = test_ds.batch(BATCH_SIZE)
test_ds = test_ds.prefetch(tf.data.AUTOTUNE)

fg, ax = plt.subplots(1,2, figsize=(8,16))
for image, mask in test_ds.take(1):
    ax[0].imshow(image[1,...])
    ax[1].imshow(tf.argmax(mask[1,...],axis=-1))

clear_output()

### swin-unet
!pip install keras-unet-collection -q -U
from keras_unet_collection import models, losses

## mobile net backbone unet
def get_upsampling_block(inp, channels):
    inp = layers.Conv2DTranspose(channels, (2,2), strides=(2,2), padding='same')(inp)
    return inp

def get_conv_block(inp, channels):
    inp = layers.Conv2D(channels, (3, 3), kernel_initializer='he_normal', padding='same')(inp)
    inp = layers.BatchNormalization()(inp)
    inp = layers.Activation('gelu')(inp)
    inp = layers.Conv2D(channels, (3, 3), kernel_initializer='he_normal', padding='same')(inp)
    inp = layers.BatchNormalization()(inp)
    inp = layers.Activation('gelu')(inp)
    return inp

def get_unet_model(input_shape):
    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)
    inp = base_model.input
    # shape(256,256,96)
    s1 = base_model.get_layer('expanded_conv_depthwise_relu').output
    # shape(128,128,144)
    s2 = base_model.get_layer('block_1_depthwise_relu').output
    # shape(64,64,192)
    s3 = base_model.get_layer('block_4_depthwise_relu').output
    # shape(32,32,576)
    d = base_model.get_layer('block_6_depthwise_relu').output

    d1 = get_upsampling_block(d, 256)
    d1 = layers.concatenate([d1, s3])
    d1 = get_conv_block(d1, 256)

    d2 = get_upsampling_block(d1, 128)
    d2 = layers.concatenate([d2, s2])
    d2 = get_conv_block(d2, 128)

    d3 = get_upsampling_block(d2, 64)
    d3 = layers.concatenate([d3, s1])
    d3 = get_conv_block(d3, 64)

    output = get_upsampling_block(d3, 32)
    output = layers.concatenate([output, inp])
    output = get_conv_block(output, 32)

    output = layers.Conv2D(num_classes, 1, padding='same')(output)
    output = layers.Softmax(axis=-1)(output)
    return keras.Model(inp, output)

tf.keras.backend.clear_session()
model = get_unet_model((512,512,3))
model.summary()

tf.config.experimental_run_functions_eagerly(True)
def focal_loss(predict, true):
    error = keras.losses.categorical_crossentropy(predict, true)
    pt = tf.exp(-error)
    focal_loss = (1 - pt) ** 2 * error
    return tf.reduce_mean(focal_loss)

def mean_iou(predict, true):
    predict = tf.argmax(predict, axis=-1)
    true = tf.argmax(true, axis=-1)
    return keras.metrics.MeanIoU(num_classes=num_classes)(predict, true)

model.compile(optimizer='adam',
             loss=focal_loss,
             metrics=['accuracy', mean_iou])

history = model.fit(train_ds, validation_data=test_ds, epochs=1)

history = model.fit(train_ds, validation_data=test_ds, epochs=2)

history = model.fit(train_ds, validation_data=test_ds, epochs=3)

history = model.fit(train_ds, validation_data=test_ds, epochs=4)

history = model.fit(train_ds, validation_data=test_ds, epochs=5)

model.save("version2.h5")

for images, masks in test_ds.take(1):
    pred = model.predict(images)

predictions = np.argmax(pred, axis=-1)
labels = np.argmax(masks, axis=-1)
print(labels.shape)
print(predictions.shape)

fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()



fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()





fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()



fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()



fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()

fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 4 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()

fig, ax = plt.subplots(BATCH_SIZE, 3, figsize=(15, 8 * BATCH_SIZE))
for j in range(BATCH_SIZE):
    ax[j, 0].imshow(images[j, ...].numpy())
    ax[j, 1].imshow(predictions[j, ...].astype('uint8'))
    ax[j, 2].imshow(labels[j, ...])
    ax[j, 0].set_title('Original image')
    ax[j, 1].set_title('Prediction')
    ax[j, 2].set_title('Ground truth')
plt.show()



def multi_unet_model(n_classes=23, IMG_HEIGHT=512, IMG_WIDTH=512, IMG_CHANNELS=3):
#Build the model
    inputs = layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = inputs

    #Contraction path
    c1 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
    c1 = layers.Dropout(0.1)(c1)  # Original 0.1
    c1 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)

    c2 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
    c2 = layers.Dropout(0.1)(c2)  # Original 0.1
    c2 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)

    c3 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
    c3 = layers.Dropout(0.1)(c3)
    c3 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)

    c4 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
    c4 = layers.Dropout(0.1)(c4)
    c4 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)

    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
    c5 = layers.Dropout(0.3)(c5)
    c5 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

    #Expansive path
    u6 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
    c6 = layers.Dropout(0.1)(c6)
    c6 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

    u7 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
    c7 = layers.Dropout(0.2)(c7)
    c7 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

    u8 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
    c8 = layers.Dropout(0.1)(c8)  # Original 0.1
    c8 = layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

    u9 = layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = layers.concatenate([u9, c1], axis=3)
    c9 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
    c9 = layers.Dropout(0.1)(c9)  # Original 0.1
    c9 = layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)

    outputs = layers.Conv2D(n_classes, (1, 1), activation='softmax')(c9)

    model = keras.Model(inputs=[inputs], outputs=[outputs])

    #NOTE: Compile the model in the main program to make it easy to test with various loss functions
    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])

    model.summary()

    return model


tf.keras.backend.clear_session()
model = multi_unet_model()

tf.config.experimental_run_functions_eagerly(True)
def focal_loss(predict, true):
    error = keras.losses.categorical_crossentropy(predict, true)
    pt = tf.exp(-error)
    focal_loss = (1 - pt) ** 2 * error
    return tf.reduce_mean(focal_loss)

def mean_iou(predict, true):
    predict = tf.argmax(predict, axis=-1)
    true = tf.argmax(true, axis=-1)
    return keras.metrics.MeanIoU(num_classes=num_classes)(predict, true)

model.compile(optimizer='adam',
             loss=focal_loss,
             metrics=['accuracy', mean_iou])

history = model.fit(train_ds, validation_data=test_ds, epochs=2)

def get_unet_classification_model(input_shape, num_classes_segmentation, num_classes_classification):
    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)
    inp = base_model.input
    # Intermediate layers for segmentation
    s1 = base_model.get_layer('expanded_conv_depthwise_relu').output
    s2 = base_model.get_layer('block_1_depthwise_relu').output
    s3 = base_model.get_layer('block_4_depthwise_relu').output
    d = base_model.get_layer('block_6_depthwise_relu').output

    # Decoder for segmentation
    d1 = get_upsampling_block(d, 256)
    d1 = layers.concatenate([d1, s3])
    d1 = get_conv_block(d1, 256)

    d2 = get_upsampling_block(d1, 128)
    d2 = layers.concatenate([d2, s2])
    d2 = get_conv_block(d2, 128)

    d3 = get_upsampling_block(d2, 64)
    d3 = layers.concatenate([d3, s1])
    d3 = get_conv_block(d3, 64)

    output_segmentation = get_upsampling_block(d3, 32)
    output_segmentation = layers.concatenate([output_segmentation, inp])
    output_segmentation = get_conv_block(output_segmentation, 32)

    output_segmentation = layers.Conv2D(num_classes_segmentation, 1, padding='same')(output_segmentation)
    output_segmentation = layers.Softmax(axis=-1, name='segmentation_output')(output_segmentation)

    # Classifier
    x = layers.GlobalAveragePooling2D()(d)
    x = layers.Dense(512, activation='relu')(x)
    output_classification = layers.Dense(num_classes_classification, activation='softmax', name='classification_output')(x)

    return keras.Model(inputs=inp, outputs=[output_segmentation, output_classification])

tf.keras.backend.clear_session()
model = get_unet_classification_model((512, 512, 3), num_classes_segmentation=5, num_classes_classification=10)
model.summary()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class InvolutionLayer(layers.Layer):
    def __init__(self, channels, kernel_size, stride):
        super(InvolutionLayer, self).__init__()
        self.channels = channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.group_channels = channels // 1  # Assuming group size is 1 for simplicity
        self.conv1 = layers.Conv2D(filters=self.group_channels, kernel_size=1)
        self.conv2 = layers.Conv2D(filters=self.kernel_size * self.kernel_size * self.group_channels,
                                   kernel_size=1,
                                   padding='same')

    def call(self, x):
        # Reduction phase
        if self.stride > 1:
            x = layers.AveragePooling2D(pool_size=self.stride, strides=self.stride)(x)

        # Generate involution kernel
        kernel = self.conv1(x)
        kernel = self.conv2(kernel)
        kernel = tf.reshape(kernel, [-1, tf.shape(kernel)[1], tf.shape(kernel)[2],
                                     self.kernel_size, self.kernel_size, self.group_channels])

        # Unfold input to apply the kernel
        input_unfold = tf.image.extract_patches(images=x,
                                                sizes=[1, self.kernel_size, self.kernel_size, 1],
                                                strides=[1, self.stride, self.stride, 1],
                                                rates=[1, 1, 1, 1],
                                                padding='SAME')
        input_unfold = tf.reshape(input_unfold, [-1, tf.shape(input_unfold)[1], tf.shape(input_unfold)[2],
                                                 self.kernel_size, self.kernel_size, self.channels])

        # Apply involution kernel on input
        out = kernel * input_unfold
        out = tf.reduce_sum(out, axis=[3, 4])
        return out

import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Concatenate, Conv2DTranspose, Softmax

# Define Involution layer
class Involution(tf.keras.layers.Layer):
    def __init__(self, channels, reduction_ratio=4, kernel_size=3, **kwargs):
        super(Involution, self).__init__(**kwargs)
        self.channels = channels
        self.reduction_ratio = reduction_ratio
        self.kernel_size = kernel_size
        self.gap = GlobalAveragePooling2D()

    def build(self, input_shape):
        self.embedded_dimension = max(input_shape[-1] // self.reduction_ratio, 1)
        self.depthwise_conv = tf.keras.layers.DepthwiseConv2D(self.kernel_size, padding='same', use_bias=False)
        self.pointwise_conv = tf.keras.layers.Conv2D(self.channels, kernel_size=1, use_bias=False)

    def call(self, inputs):
        x = self.gap(inputs)
        x = tf.keras.layers.Reshape((1, 1, inputs.shape[-1]))(x)
        x = self.pointwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = self.depthwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('sigmoid')(x)
        x = tf.keras.layers.Multiply()([inputs, x])
        return x

# Define downsampling block with Involution
def downsampling_block(inputs, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    downsampled = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(inv_output)
    return downsampled

# Define upsampling block with Involution
def upsampling_block(inputs, skip_connection, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    upsample = Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2, 2), padding='same')(inv_output)
    concat = Concatenate()([upsample, skip_connection])
    return concat

# Define classification head
def classification_head(inputs, num_classes):
    conv_block = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv_block = tf.keras.layers.BatchNormalization()(conv_block)
    conv_block = tf.keras.layers.LeakyReLU(alpha=0.1)(conv_block)

    global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()(conv_block)
    fully_connected = tf.keras.layers.Dense(128)(global_avg_pool)
    fully_connected = tf.keras.layers.LeakyReLU(alpha=0.1)(fully_connected)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fully_connected)

    return output

# Define segmentation head
def segmentation_head(inputs, num_classes):
    conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    conv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv1)

    conv2 = tf.keras.layers.Conv2D(filters=num_classes, kernel_size=(3, 3), padding='same')(conv1)
    conv2 = tf.keras.layers.BatchNormalization()(conv2)
    conv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv2)

    output = tf.keras.layers.Softmax()(conv2)

    return output

# Build the model
def build_model(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoding path
    enc_block1 = downsampling_block(inputs, 64)
    enc_block2 = downsampling_block(enc_block1, 128)
    # Add more downsampling blocks as needed

    # Classification head
    classification_output = classification_head(enc_block2, num_classes)

    # Decoding path
    dec_block1 = upsampling_block(enc_block2, enc_block1, 128)
    # Add more upsampling blocks as needed

    # Segmentation head
    segmentation_output = segmentation_head(dec_block1, num_classes)

    model = tf.keras.Model(inputs=inputs, outputs=[classification_output, segmentation_output])
    return model

# Example usage:
input_shape = (256, 256, 3)
num_classes = 5  # Example number of classes
model = build_model(input_shape, num_classes)
model.summary()

import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Concatenate, Conv2DTranspose, Softmax

# Define Involution layer
class Involution(tf.keras.layers.Layer):
    def __init__(self, channels, reduction_ratio=4, kernel_size=3, **kwargs):
        super(Involution, self).__init__(**kwargs)
        self.channels = channels
        self.reduction_ratio = reduction_ratio
        self.kernel_size = kernel_size
        self.gap = GlobalAveragePooling2D()

    def build(self, input_shape):
        self.embedded_dimension = max(input_shape[-1] // self.reduction_ratio, 1)
        self.depthwise_conv = tf.keras.layers.DepthwiseConv2D(self.kernel_size, padding='same', use_bias=False)
        self.pointwise_conv = tf.keras.layers.Conv2D(self.channels, kernel_size=1, use_bias=False)

    def call(self, inputs):
        x = self.gap(inputs)
        x = tf.keras.layers.Reshape((1, 1, inputs.shape[-1]))(x)
        x = self.pointwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = self.depthwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('sigmoid')(x)
        # Resize the output to match the shape of inputs
        x = tf.keras.layers.UpSampling2D(size=(inputs.shape[1] // x.shape[1], inputs.shape[2] // x.shape[2]))(x)
        x = tf.keras.layers.Multiply()([inputs, x])
        return x

# Define downsampling block with Involution
def downsampling_block(inputs, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    downsampled = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(inv_output)
    return downsampled

# Define upsampling block with Involution
def upsampling_block(inputs, skip_connection, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    upsample = Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2, 2), padding='same')(inv_output)
    concat = Concatenate()([upsample, skip_connection])
    return concat

# Define classification head
def classification_head(inputs, num_classes):
    conv_block = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv_block = tf.keras.layers.BatchNormalization()(conv_block)
    conv_block = tf.keras.layers.LeakyReLU(alpha=0.1)(conv_block)

    global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()(conv_block)
    fully_connected = tf.keras.layers.Dense(128)(global_avg_pool)
    fully_connected = tf.keras.layers.LeakyReLU(alpha=0.1)(fully_connected)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(fully_connected)

    return output

# Define segmentation head
def segmentation_head(inputs, num_classes):
    conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    conv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv1)

    conv2 = tf.keras.layers.Conv2D(filters=num_classes, kernel_size=(3, 3), padding='same')(conv1)
    conv2 = tf.keras.layers.BatchNormalization()(conv2)
    conv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv2)

    output = tf.keras.layers.Softmax()(conv2)

    return output

# Build the model
def build_model(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoding path
    enc_block1 = downsampling_block(inputs, 64)
    enc_block2 = downsampling_block(enc_block1, 128)
    # Add more downsampling blocks as needed

    # Classification head
    classification_output = classification_head(enc_block2, num_classes)

    # Decoding path
    dec_block1 = upsampling_block(enc_block2, enc_block1, 128)
    # Add more upsampling blocks as needed

    # Segmentation head
    segmentation_output = segmentation_head(dec_block1, num_classes)

    model = tf.keras.Model(inputs=inputs, outputs=[classification_output, segmentation_output])
    return model

# Example usage:
input_shape = (256, 256, 2)
num_classes = 2  # Example number of classes
model = build_model(input_shape, num_classes)
model.summary()

import tensorflow as tf
from tensorflow.keras.layers import BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Concatenate, Conv2DTranspose, Activation

# Define Involution layer
class Involution(tf.keras.layers.Layer):
    def __init__(self, channels, reduction_ratio=4, kernel_size=3, **kwargs):
        super(Involution, self).__init__(**kwargs)
        self.channels = channels
        self.reduction_ratio = reduction_ratio
        self.kernel_size = kernel_size
        self.gap = GlobalAveragePooling2D()

    def build(self, input_shape):
        self.embedded_dimension = max(input_shape[-1] // self.reduction_ratio, 1)
        self.depthwise_conv = tf.keras.layers.DepthwiseConv2D(self.kernel_size, padding='same', use_bias=False)
        self.pointwise_conv = tf.keras.layers.Conv2D(self.channels, kernel_size=1, use_bias=False)

    def call(self, inputs):
        x = self.gap(inputs)
        x = tf.keras.layers.Reshape((1, 1, inputs.shape[-1]))(x)
        x = self.pointwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('relu')(x)
        x = self.depthwise_conv(x)
        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.Activation('sigmoid')(x)
        # Resize the output to match the shape of inputs
        x = tf.keras.layers.UpSampling2D(size=(inputs.shape[1] // x.shape[1], inputs.shape[2] // x.shape[2]))(x)
        x = tf.keras.layers.Multiply()([inputs, x])
        return x

# Define downsampling block with Involution
def downsampling_block(inputs, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    downsampled = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(inv_output)
    return downsampled

# Define upsampling block with Involution
def upsampling_block(inputs, skip_connection, filters):
    involution = Involution(channels=filters)
    inv_output = involution(inputs)
    upsample = Conv2DTranspose(filters, kernel_size=(3, 3), strides=(2, 2), padding='same')(inv_output)
    concat = Concatenate()([upsample, skip_connection])
    return concat

# Define classification head
def classification_head(inputs):
    conv_block = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv_block = tf.keras.layers.BatchNormalization()(conv_block)
    conv_block = tf.keras.layers.LeakyReLU(alpha=0.1)(conv_block)

    global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()(conv_block)
    fully_connected = tf.keras.layers.Dense(128)(global_avg_pool)
    fully_connected = tf.keras.layers.LeakyReLU(alpha=0.1)(fully_connected)
    output = tf.keras.layers.Dense(1, activation='sigmoid')(fully_connected)  # Binary classification
    return output

# Define segmentation head
def segmentation_head(inputs):
    conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
    conv1 = tf.keras.layers.BatchNormalization()(conv1)
    conv1 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv1)

    conv2 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding='same')(conv1)  # Single output neuron
    conv2 = tf.keras.layers.BatchNormalization()(conv2)
    conv2 = tf.keras.layers.LeakyReLU(alpha=0.1)(conv2)

    output = tf.keras.layers.Activation('sigmoid')(conv2)  # Use sigmoid activation for binary segmentation
    return output

# Build the model
def build_model(input_shape):
    inputs = tf.keras.Input(shape=input_shape)

    # Encoding path
    enc_block1 = downsampling_block(inputs, 64)
    enc_block2 = downsampling_block(enc_block1, 128)
    # Add more downsampling blocks as needed

    # Classification head
    classification_output = classification_head(enc_block2)

    # Decoding path
    dec_block1 = upsampling_block(enc_block2, enc_block1, 128)
    # Add more upsampling blocks as needed

    # Segmentation head
    segmentation_output = segmentation_head(dec_block1)

    model = tf.keras.Model(inputs=inputs, outputs=[classification_output, segmentation_output])
    return model

# Example usage:
input_shape = (256, 256, 3)
model = build_model(input_shape)
model.summary()



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the Involution Layer
class InvolutionLayer(layers.Layer):
    def __init__(self, channels, kernel_size, stride):
        super(InvolutionLayer, self).__init__()
        self.channels = channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.group_channels = channels // 1  # Assuming group size is 1 for simplicity
        self.conv1 = layers.Conv2D(filters=self.group_channels, kernel_size=1)
        self.conv2 = layers.Conv2D(filters=self.kernel_size * self.kernel_size * self.group_channels,
                                   kernel_size=1, padding='same')

    def call(self, x):
        # Reduction phase
        if self.stride > 1:
            x = layers.AveragePooling2D(pool_size=self.stride, strides=self.stride)(x)

        # Generate involution kernel
        kernel = self.conv1(x)
        kernel = self.conv2(kernel)
        kernel = tf.reshape(kernel, [-1, tf.shape(kernel)[1], tf.shape(kernel)[2],
                                     self.kernel_size, self.kernel_size, self.group_channels])

        # Unfold input to apply the kernel
        input_unfold = tf.image.extract_patches(images=x,
                                                sizes=[1, self.kernel_size, self.kernel_size, 1],
                                                strides=[1, self.stride, self.stride, 1],
                                                rates=[1, 1, 1, 1],
                                                padding='SAME')
        input_unfold = tf.reshape(input_unfold, [-1, tf.shape(input_unfold)[1], tf.shape(input_unfold)[2],
                                                 self.kernel_size, self.kernel_size, self.channels])

        # Apply involution kernel on input
        out = kernel * input_unfold
        out = tf.reduce_sum(out, axis=[3, 4])
        return out

# Utility functions for the model
def get_upsampling_block(input_tensor, filters):
    x = layers.UpSampling2D()(input_tensor)
    x = InvolutionLayer(channels=filters, kernel_size=3, stride=1)(x)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    return x

def get_conv_block(input_tensor, filters):
    x = InvolutionLayer(channels=filters, kernel_size=3, stride=1)(input_tensor)
    x = layers.BatchNormalization()(x)
    x = layers.ReLU()(x)
    return x

# Define the U-Net model with Involution Neural Network
def get_unet_involution_model(input_shape, num_classes_segmentation, num_classes_classification):
    inputs = keras.Input(shape=input_shape)

    # Encoder
    e1 = get_conv_block(inputs, 32)
    p1 = layers.MaxPooling2D()(e1)
    e2 = get_conv_block(p1, 64)
    p2 = layers.MaxPooling2D()(e2)
    e3 = get_conv_block(p2, 128)
    p3 = layers.MaxPooling2D()(e3)
    e4 = get_conv_block(p3, 256)

    # Bottleneck
    b = get_conv_block(e4, 512)

    # Decoder
    d1 = get_upsampling_block(b, 256)
    d1 = layers.concatenate([d1, e3])
    d1 = get_conv_block(d1, 256)

    d2 = get_upsampling_block(d1, 128)
    d2 = layers.concatenate([d2, e2])
    d2 = get_conv_block(d2, 128)

    d3 = get_upsampling_block(d2, 64)
    d3 = layers.concatenate([d3, e1])
    d3 = get_conv_block(d3, 64)

    output_segmentation = layers.Conv2D(num_classes_segmentation, 1, padding='same')(d3)
    output_segmentation = layers.Softmax(axis=-1, name='segmentation_output')(output_segmentation)

    # Classification head
    x = layers.GlobalAveragePooling2D()(b)
    x = layers.Dense(512, activation='relu')(x)
    output_classification = layers.Dense(num_classes_classification, activation='softmax', name='classification_output')(x)

    # Construct model
    model = keras.Model(inputs=inputs, outputs=[output_segmentation, output_classification])
    return model

# Clear previous session and define model parameters
tf.keras.backend.clear_session()
input_shape = (512, 512, 3)
num_classes_segmentation = 2
num_classes_classification = 10

# Get the model
model = get_unet_involution_model(input_shape, num_classes_segmentation, num_classes_classification)
model.summary()

import tensorflow as tf
from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, DepthwiseConv2D, Conv2D, BatchNormalization, Activation, Multiply, UpSampling2D

class Involution(tf.keras.layers.Layer):
    def __init__(self, channels, reduction_ratio=4, kernel_size=3, **kwargs):
        super(Involution, self).__init__(**kwargs)
        self.channels = channels
        self.reduction_ratio = reduction_ratio
        self.kernel_size = kernel_size
        self.gap = GlobalAveragePooling2D()

    def build(self, input_shape):
        self.embedded_dimension = max(input_shape[-1] // self.reduction_ratio, 1)
        self.depthwise_conv = DepthwiseConv2D(self.kernel_size, padding='same', use_bias=False)
        self.pointwise_conv = Conv2D(self.channels, kernel_size=1, use_bias=False)

    def call(self, inputs):
        x = self.gap(inputs)
        x = Reshape((1, 1, inputs.shape[-1]))(x)
        x = self.pointwise_conv(x)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = self.depthwise_conv(x)
        x = BatchNormalization()(x)
        x = Activation('sigmoid')(x)
        x = UpSampling2D(size=(inputs.shape[1] // x.shape[1], inputs.shape[2] // x.shape[2]))(x)
        x = Multiply()([inputs, x])
        return x

# Test the Involution layer
input_shape = (256, 256, 3)
inputs = tf.keras.Input(shape=input_shape)
involution_layer = Involution(channels=64)
outputs = involution_layer(inputs)
model = tf.keras.Model(inputs=inputs, outputs=outputs)
model.summary()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the Involution Layer
class InvolutionLayer(layers.Layer):
    def __init__(self, channels, kernel_size, stride):
        super(InvolutionLayer, self).__init__()
        self.channels = channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.group_channels = channels // 1  # Assuming group size is 1 for simplicity
        self.conv1 = layers.Conv2D(filters=self.group_channels, kernel_size=1, use_bias=False)
        self.conv2 = layers.Conv2D(filters=self.kernel_size * self.kernel_size * self.group_channels,
                                   kernel_size=1, padding='same', use_bias=False)

    def call(self, x):
        # Reduction phase
        if self.stride > 1:
            x = layers.AveragePooling2D(pool_size=self.stride, strides=self.stride)(x)

        # Generate involution kernel
        kernel = self.conv1(x)
        kernel = self.conv2(kernel)
        kernel = tf.reshape(kernel, [-1, tf.shape(kernel)[1], tf.shape(kernel)[2],
                                     self.kernel_size, self.kernel_size, self.group_channels])

        # Unfold input to apply the kernel
        input_unfold = tf.image.extract_patches(images=x,
                                                sizes=[1, self.kernel_size, self.kernel_size, 1],
                                                strides=[1, self.stride, self.stride, 1],
                                                rates=[1, 1, 1, 1],
                                                padding='SAME')
        input_unfold = tf.reshape(input_unfold, [-1, tf.shape(input_unfold)[1], tf.shape(input_unfold)[2],
                                                 self.kernel_size, self.kernel_size, self.channels])

        # Apply involution kernel on input
        out = kernel * input_unfold
        out = tf.reduce_sum(out, axis=[3, 4])
        return out

# Simplified U-Net Model
def get_simplified_unet(input_shape, num_classes_segmentation, num_classes_classification):
    inputs = keras.Input(shape=input_shape)

    # Encoder
    e1 = InvolutionLayer(channels=16, kernel_size=3, stride=1)(inputs)
    p1 = layers.MaxPooling2D()(e1)
    e2 = InvolutionLayer(channels=32, kernel_size=3, stride=1)(p1)

    # Bottleneck
    b = layers.MaxPooling2D()(e2)
    b = InvolutionLayer(channels=64, kernel_size=3, stride=1)(b)

    # Decoder
    d1 = layers.UpSampling2D()(b)
    d1 = layers.concatenate([d1, e2])
    d1 = InvolutionLayer(channels=32, kernel_size=3, stride=1)(d1)

    d2 = layers.UpSampling2D()(d1)
    d2 = layers.concatenate([d2, e1])
    d2 = InvolutionLayer(channels=16, kernel_size=3, stride=1)(d2)

    # Segmentation Output
    output_segmentation = layers.Conv2D(num_classes_segmentation, 1, padding='same')(d2)
    output_segmentation = layers.Softmax(axis=-1, name='segmentation_output')(output_segmentation)

    # Classification Output
    c = layers.GlobalAveragePooling2D()(b)
    c = layers.Dense(128, activation='relu')(c)
    output_classification = layers.Dense(num_classes_classification, activation='softmax', name='classification_output')(c)

    # Construct model
    model = keras.Model(inputs=inputs, outputs=[output_segmentation, output_classification])

    return model

# Clear previous session and define model parameters
tf.keras.backend.clear_session()
input_shape = (3840, 3840, 3)  # Reduced input size to control the number of parameters
num_classes_segmentation = 2
num_classes_classification = 2

# Get the model
model = get_simplified_unet(input_shape, num_classes_segmentation, num_classes_classification)
model.summary()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Define the Involution Layer
class InvolutionLayer(layers.Layer):
    def __init__(self, channels, kernel_size, stride):
        super(InvolutionLayer, self).__init__()
        self.channels = channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.conv1 = layers.Conv2D(filters=channels // 2, kernel_size=1, use_bias=False)
        self.conv2 = layers.Conv2D(filters=kernel_size * kernel_size * channels, kernel_size=1, padding='same', use_bias=False)

    def call(self, x):
        if self.stride > 1:
            x = layers.AveragePooling2D(pool_size=self.stride, strides=self.stride)(x)

        kernel = self.conv1(x)
        kernel = self.conv2(kernel)
        kernel = tf.reshape(kernel, [-1, tf.shape(kernel)[1], tf.shape(kernel)[2],
                                     self.kernel_size, self.kernel_size, self.channels])

        input_unfold = tf.image.extract_patches(images=x, sizes=[1, self.kernel_size, self.kernel_size, 1],
                                                strides=[1, self.stride, self.stride, 1],
                                                rates=[1, 1, 1, 1], padding='SAME')
        input_unfold = tf.reshape(input_unfold, [-1, tf.shape(input_unfold)[1], tf.shape(input_unfold)[2],
                                                 self.kernel_size, self.kernel_size, self.channels])

        out = kernel * input_unfold
        out = tf.reduce_sum(out, axis=[3, 4])
        return out

def get_adjusted_unet(input_shape, num_classes_segmentation, num_classes_classification):
    inputs = keras.Input(shape=input_shape)

    # Encoder
    e1 = InvolutionLayer(channels=8, kernel_size=3, stride=1)(inputs)
    p1 = layers.MaxPooling2D()(e1)
    e2 = InvolutionLayer(channels=16, kernel_size=3, stride=1)(p1)

    # Bottleneck
    b = layers.MaxPooling2D()(e2)
    b = InvolutionLayer(channels=32, kernel_size=3, stride=1)(b)

    # Decoder
    d1 = layers.UpSampling2D()(b)
    d1 = layers.concatenate([d1, e2])
    d1 = InvolutionLayer(channels=16, kernel_size=3, stride=1)(d1)

    d2 = layers.UpSampling2D()(d1)
    d2 = layers.concatenate([d2, e1])
    d2 = InvolutionLayer(channels=8, kernel_size=3, stride=1)(d2)

    # Segmentation Output
    output_segmentation = layers.Conv2D(num_classes_segmentation, 1, padding='same')(d2)
    output_segmentation = layers.Softmax(axis=-1, name='segmentation_output')(output_segmentation)

    # Classification Output
    c = layers.GlobalAveragePooling2D()(b)
    c = layers.Dense(64, activation='relu')(c)
    output_classification = layers.Dense(num_classes_classification, activation='softmax', name='classification_output')(c)

    model = keras.Model(inputs=inputs, outputs=[output_segmentation, output_classification])
    return model

tf.keras.backend.clear_session()
input_shape = (512, 512, 3)
num_classes_segmentation = 2
num_classes_classification = 2

model = get_adjusted_unet(input_shape, num_classes_segmentation, num_classes_classification)
model.summary()

tf.config.experimental_run_functions_eagerly(True)
def focal_loss(predict, true):
    error = keras.losses.categorical_crossentropy(predict, true)
    pt = tf.exp(-error)
    focal_loss = (1 - pt) ** 2 * error
    return tf.reduce_mean(focal_loss)

def mean_iou(predict, true):
    predict = tf.argmax(predict, axis=-1)
    true = tf.argmax(true, axis=-1)
    return keras.metrics.MeanIoU(num_classes=num_classes)(predict, true)

model.compile(optimizer='adam',
             loss=focal_loss,
             metrics=['accuracy', mean_iou])

history = model.fit(train_ds, validation_data=test_ds, epochs=2)

